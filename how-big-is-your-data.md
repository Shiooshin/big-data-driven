Досвід останніх проектів показує, що все менше проектів вихваляються величезними об'ємами даних, які потрапляють в Платформу Даних. Робота з даними стала важливим аспектом навіть малих компаній. Всі хочуть бути "data driven" незалежно від масштабу. Значно менше стало проектів де потрібно кластер з 30-ти машин, що обробляють нові дані щоденно. Натомість більше запитів розробити аналітичну платформу для компаній, що сумарно в день ледве назбирують гігабайти даних. Проте обидвом описаним компаніям важлива аналітика. 

Подібні думки викладені у [нещодавному пості](https://towardsdatascience.com/i-dont-care-how-big-your-data-is-f487aa7ea74e). Якщо опустити посилання та рекламу власного продукту, у статті йдемться про:
- Зміну масштабів проектів пов'язаних з Інженерією Даних. Значно більше запитів щодо аналітики, яка обмежується кількоми Гішабайтами даних в день(що на виході дасть всього лиш мегабайти інформації), 
- Тенденції у ML фреймворках. Зростання та якість ML фреймворків швидко зростає і на навчання моделей йде значно менше обчислювальних ресурс ніж раніше
- Data Governance. Досі велика частина Data Governance практик імплементується мануально. Це завжди болісно, важко, часозатратно. 