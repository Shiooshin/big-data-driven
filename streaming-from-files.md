Після невеликої відпустки і різдвяних свят вертаюсь до вас з новими новинами та цікавими статтями. Контенту дуже багато, тож буду наздоганяти.

Я звик, що потокова обробка даних даних це завжди про event bus. Тому в голові в мене відлунюється Apache Kafka або аналоги, коли мова йде про потік даних, який згодом можна обробити з допомогою Spark Streaming. Але я натрапив на [цікавий підхід з прикладами коду](https://towardsdatascience.com/streaming-iceberg-table-an-alternative-to-kafka-be54a1624917), що виключає event bus. Spark Streaming підтримує вичитку нових даних напряму з файлів. Сам підхід не є оптимальний, враховуючи що завжди треба тримати курсори, чекпоінти і інші метадані. І тут на допомогу приходить Apache Iceberg, який забирає велику частини метаданих на себе, що в свою чергу розвантажує Spark. Ну і звісно додає свої переваги типу ролбеку та data lineage. 