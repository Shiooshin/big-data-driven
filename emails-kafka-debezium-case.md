[Приклад event-driven архітектури](https://medium.com/yotpoengineering/scheduling-millions-of-messages-with-kafka-debezium-6d1a105160c) з використанням Kafka та потоком даних ~1 000 000 подій/хв. В статті приведені альтернативи та проблеми, з якими команда стикалась при виборі стеку технологій для вирішення даної задачі. 

Я не дуже згоден саме з фінальним рішенням. Особливо обгрунтуванням _"ми і так використовуєм Kafka та Debezium, тому вирішили взяти саме їх"_. Вибір Apache Kafka доцільний звісно, як для проблеми, так і для подальшого розширення системи. Як на мене, сховище даних зайве, і додавати його тільки для того аби використати Devbezium - занадто. 

Я би використовував Kafka + Kafka Streams. В такому випадку архітектура залишилась event-driven, а також отримали гнучку обробку даних в плані розширення та навантаження. Ще я не великий прихильник Debezium. Особливо коли з ним потрібно праацювати у масштабі production, де є великі реляційні сховища, налаштована реплікація чи шардинг.  